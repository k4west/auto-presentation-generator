# agents.py

import json
from dotenv import load_dotenv
from typing import List
from pydantic import ValidationError
from langchain_openai import ChatOpenAI, OpenAI
from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper
from .graph_state import OutlineModel, SlideContentModel, FinalMarpModel

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… LLM ê¸°ë³¸ ì„¤ì • (ChatOpenAI / OpenAI)
# JSON í˜•ì‹ LLM (ì½”ë“œ ë¸”ë¡ / ì„¤ëª… ì—†ì´ "json_object"ë§Œ ë°˜í™˜)
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
llm_json = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
    model_kwargs={"response_format": {"type": "json_object"}}
)
openai_llm = OpenAI(model="gpt-4o-mini", temperature=0)

# âœ… DALLÂ·E API ì„¤ì • (ì´ë¯¸ì§€ ìƒì„±ìš©)
dalle = DallEAPIWrapper(model="dall-e-3", size="1024x1024", quality="standard", n=1)


# ğŸŸ¢ ê°œìš”ë“¤(OutlineModel ë¦¬ìŠ¤íŠ¸)ì„ JSONìœ¼ë¡œ ë°˜í™˜
def generate_outline(topic: str, style: str, last_msg: str) -> List[OutlineModel]:
    """
    ê°œìš”ë“¤(OutlineModel ë¦¬ìŠ¤íŠ¸)ì„ JSONìœ¼ë¡œ ë°˜í™˜.
    ë§ˆì§€ë§‰ ë©”ì‹œì§€(last_msg)ë¥¼ ì¶”ê°€ ë¬¸ë§¥ìœ¼ë¡œ ê³ ë ¤.
    """
    prompt = f"""Return a JSON array of outline items for a {style} style presentation on '{topic}'.
The user has an additional message or context: '{last_msg}'

return type: arrayed objects
{{
    title (string):  "Outline Title"
    content (string):  "Actual text (markdown/HTML)"
    images (int):  "Number of images per outline"
    image_positions (list[string]):  "Positions where images will appear"
    pages (int):  "Number of pages if content is large"
}}
Do not include extra keys. No code blocks. JSON only.
"""

    resp = llm_json.invoke(prompt).content
    try:
        data = json.loads(resp)
        if isinstance(data, dict):
            data = data[[*data.keys()][0]]
        # print(data)
        return data
        outlines = []
        for item in data:
            outlines.append(OutlineModel(**item))
        return outlines
    except (json.JSONDecodeError, ValidationError):
        return []


# ğŸŸ¢ ê°œìš” ê´€ë ¨ì„± ê²€ì‚¬ Agent
def check_relevance(outline: str, topic: str) -> bool:
    """ê°œìš”ê°€ ì£¼ì œì™€ ê´€ë ¨ì´ ìˆëŠ”ì§€ í‰ê°€"""
    prompt = (
        f"Does the following outline accurately match the topic '{topic}'? "
        f"Respond with 'Yes' if relevant and 'No' if not.\n\nOutline:\n{outline}"
    )
    response = llm.invoke(prompt).content
    return "yes" in response.lower()

# ğŸŸ¢ ê°œìš” í™•ì¥ Agent
def refine_outline(outline: str) -> str:
    """ê¸°ì¡´ ê°œìš”ë¥¼ ë” ì„¸ë¶€ì ìœ¼ë¡œ í™•ì¥"""
    prompt = f"Expand and enrich this `content` for a presentation with more details.\nReturn only the content, without any other explanation.\ncontent:{outline}"
    return llm.invoke(prompt).content

# ğŸŸ¢ ìŠ¬ë¼ì´ë“œ ë¶„í•  Agent (OutlineModel â†’ list[str])
def split_outline_to_slides(outline_item: OutlineModel) -> List[str]:
    """
    pages ìˆ˜ì— ë§ì¶° ìŠ¬ë¼ì´ë“œë¥¼ ë¶„í•  (ê°„ë‹¨ ì˜ˆì‹œ).
    ë‚´ìš©ì´ ê¸¸ë©´ LLMì— ë§¡ê²¨ë„ ë˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ë¶„í• ë§Œ ì˜ˆì‹œ.
    """
    slides = []
    lines = outline_item.content.split("\n")
    chunk_size = max(1, len(lines)//outline_item.pages)

    idx = 0
    for p in range(outline_item.pages):
        part = "\n".join(lines[idx : idx + chunk_size])
        idx += chunk_size
        slide_text = f"# {outline_item.title}\n\n{part}"
        slides.append(slide_text)
    return slides

# ğŸŸ¢ ë””ìì¸ ì ìš© Agent (ë¹„ë™ê¸°)
async def apply_design_async(slides: List[str], style: str) -> List[str]:
    """
    ìŠ¬ë¼ì´ë“œì— ë””ìì¸ ìŠ¤íƒ€ì¼ì„ ì ìš© (ë¹„ë™ê¸°)
    """
    prompt = (
        f"Apply a {style} design theme to the following slides. "
        "Format them properly for a professional presentation:\n\n"
        f"{slides}"
    )
    resp = await llm.ainvoke(prompt)
    return resp.content.split("\n")

# ğŸŸ¢ ì´ë¯¸ì§€ ìƒì„± Prompt ìƒì„± ë° í˜¸ì¶œ (ë¹„ë™ê¸°)
async def generate_image_async(topic: str, thread_id: str) -> str:
    """í”„ë ˆì  í…Œì´ì…˜ ì£¼ì œì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±"""
    # LLMì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt_for_image = (
        f"Create a detailed description for an AI-generated image that represents '{topic}'. "
        "Make sure the description is visually descriptive, specifying colors, composition, and context."
    )
    image_description_resp = await llm.ainvoke(prompt_for_image)
    image_description = image_description_resp.content

    # DALLÂ·Eì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„±
    return dalle.run(image_description)

# ğŸŸ¢ ìš”ì•½ ìŠ¬ë¼ì´ë“œ ìƒì„± Agent
def generate_summary(slides: List[str]) -> str:
    """í”„ë ˆì  í…Œì´ì…˜ì˜ ìš”ì•½ ìŠ¬ë¼ì´ë“œë¥¼ ìƒì„±"""
    prompt = (
        "Generate a concise summary slide that captures the key points "
        "from the following slides:\n\n"
        f"{slides}"
    )
    return llm.invoke(prompt).content

# ğŸŸ¢ ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± Agent
def generate_narration(slides: List[str]) -> str:
    """ë°œí‘œìê°€ ì°¸ê³ í•  ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    prompt = (
        "Write a professional and engaging presentation script based on the following slides. "
        "Ensure a natural flow and appropriate transitions:\n\n"
        f"{slides}"
    )
    return llm.invoke(prompt).content
